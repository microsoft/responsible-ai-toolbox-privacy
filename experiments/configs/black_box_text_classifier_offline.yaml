defaults:
  - workspace: M365Research-PPML-EUS
  - _self_

shared_training_parameters:
  target_epsilon: 8.0
  num_train_epochs: 3.0
  learning_rate: 5e-4
  per_device_train_batch_size: 32
  gradient_accumulation_steps: 32
  per_sample_max_grad_norm: 0.1
  max_sequence_length: 67
  delta: 1e-5
  model_name: roberta-base

shared_inference_parameters:
  batch_size: 256

game_config:
  num_models: 1
  seed: 1920
  num_concurrent_jobs_per_node: 1
  num_challenge_points_per_model: 1024

attack_config:
  mi_signal_method: tylor